version: "3.9"

services:
  kafka:
    image: apache/kafka:3.9.1
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_LOG_DIRS: /tmp/kraft-combined-logs
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0


      
  elasticsearch:
    image: elastic/elasticsearch:8.17.10
    container_name: elasticsearch
    ports:
      - "9200:9200"
    restart: unless-stopped
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - network.host=0.0.0.0
      - ES_JAVA_OPTS=-Xms1g -Xmx1g
      - cluster.routing.allocation.disk.threshold_enabled=false
      - action.destructive_requires_name=false
    volumes:
      - esdata:/usr/share/elasticsearch/data
    ulimits:
      nofile:
        soft: 65536
        hard: 65536 # 9200 port is by default

  kibana:
    image: elastic/kibana:8.17.10
    container_name: kibana
    restart: unless-stopped
    ports:
      - "5601:5601"
    environment:
     - ELASTICSEARCH_HOSTS=http://elasticsearch:9200 # kibana is http://localhost:5601/
    depends_on:
      - elasticsearch

  logstash:
    image: docker.elastic.co/logstash/logstash:8.17.10
    container_name: logstash
    volumes:
      - ../infra/logstash/pipeline/logstash.conf:/usr/share/logstash/pipeline/logstash.conf:ro
    depends_on:
      - kafka
      - elasticsearch
  
  filebeat:
    image: elastic/filebeat:8.17.10
    container_name: filebeat
    user: root
    restart: unless-stopped
    command: [ "--strict.perms=false", "-e", "-d", "publish" ]
    volumes:
      - ../infra/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    depends_on:
      - kafka

  prometheus:
    image: prom/prometheus:v3.5.0
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ../infra/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
    depends_on:
      - node-exporter

  node-exporter:
    image: prom/node-exporter:v1.9.1
    container_name: node-exporter
    pid: host
    restart: unless-stopped
    ports:
      - "9100:9100"
    volumes:
      - /:/host:ro
    command:
      - --path.rootfs=/host
      - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|run|var/lib/docker/.+|var/lib/containerd/.+|var/lib/kubelet/.+)($$|/)

  grafana:
    image: grafana/grafana:10.4.19
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      GF_SMTP_ENABLED: "true"
      GF_SMTP_HOST: "sandbox.smtp.mailtrap.io:587"
      GF_SMTP_USER: "xxx"
      GF_SMTP_PASSWORD: "xxx"
      GF_SMTP_FROM_ADDRESS: ""
      GF_SERVER_ROOT_URL: "http://localhost:3000"
    depends_on:
      - prometheus

  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: jaeger
    ports:
      - "16686:16686"
      - "4317:4317"
      - "4318:4318"


volumes:
  esdata:
